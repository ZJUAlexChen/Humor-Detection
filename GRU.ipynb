{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NV_DnIaYM_2-"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n",
        "from datasets import load_dataset\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, LSTM, GRU, Bidirectional, Dense, Embedding, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "KgNYXNTURsZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = load_dataset('humicroedit', 'subtask-1')"
      ],
      "metadata": {
        "id": "vO_zA_XoNFeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(key):\n",
        "  data = datasets[key]\n",
        "  x = []\n",
        "  y_reg = data['meanGrade']\n",
        "  y = [int(s>0.94) for s in y_reg]\n",
        "  for i in range(len(data)):\n",
        "    new_sentence = re.sub(\"<.+/>\", data[\"edit\"][i], data[\"original\"][i])\n",
        "    x.append(new_sentence)\n",
        "  return x, y, y_reg"
      ],
      "metadata": {
        "id": "XAd_Dl8pP2Fk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x_ori, train_y, train_y_reg = preprocessing('train')\n",
        "val_x_ori, val_y, val_y_reg = preprocessing('validation')\n",
        "test_x_ori, test_y, test_y_reg = preprocessing('test')"
      ],
      "metadata": {
        "id": "Vr2wGCD9Qgpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(train_x_ori)\n",
        "train_sequence = tokenizer.texts_to_sequences(train_x_ori)\n",
        "train_padded_sequence = pad_sequences(train_sequence, maxlen = 256)\n",
        "train_x = np.array(train_padded_sequence)\n",
        "train_y = np.array(train_y)\n",
        "\n",
        "test_sequence = tokenizer.texts_to_sequences(test_x_ori)\n",
        "test_padded_sequence = pad_sequences(test_sequence, maxlen = 256)\n",
        "test_x = np.array(test_padded_sequence)\n",
        "test_y = np.array(test_y)\n",
        "\n",
        "val_sequence = tokenizer.texts_to_sequences(val_x_ori)\n",
        "val_padded_sequence = pad_sequences(val_sequence, maxlen = 256)\n",
        "val_x = np.array(val_padded_sequence)\n",
        "val_y = np.array(val_y)"
      ],
      "metadata": {
        "id": "8cXbbnv9RC9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(10000, 128, input_length=256))\n",
        "model.add(GRU(128, return_sequences = False))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "6r5bA8dtR0ml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "metadata": {
        "id": "NOXlZ3Lugai9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = keras.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.RootMeanSquaredError(), tf.keras.metrics.Recall(), tf.keras.metrics.Precision(), f1_m])"
      ],
      "metadata": {
        "id": "g48kut7eSycx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_x, train_y, validation_data = (val_x, val_y), epochs=20)"
      ],
      "metadata": {
        "id": "xXlY2T61gyd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot graph\n",
        "import matplotlib.pyplot as plt\n",
        "EPOCH_NUM = 20\n",
        "train_loss = history.history['root_mean_squared_error']\n",
        "val_loss = history.history['val_root_mean_squared_error']\n",
        "train_acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epochs = range(1, EPOCH_NUM+1, 1)\n",
        "max_loss = max(max(train_loss), max(val_loss))\n",
        "\n",
        "# plot loss\n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.set_xlabel(\"Epoch\")\n",
        "ax1.set_ylabel(\"Loss\")\n",
        "ax1.set_ylim([0, max_loss+0.5])\n",
        "plt1 = ax1.plot(epochs, train_loss, 'yo-', label='Training Loss')\n",
        "plt2 = ax1.plot(epochs, val_loss, 'ro-', label='Validation Loss')\n",
        "\n",
        "# plot accuracy\n",
        "ax2 = ax1.twinx()\n",
        "ax2.set_ylabel(\"Accuracy\")\n",
        "ax2.set_ylim([0,1])\n",
        "plt3 = ax2.plot(epochs, train_acc, 'bo-', label='Training Accuracy')\n",
        "plt4 = ax2.plot(epochs, val_acc, 'co-', label='Validation Accuracy')\n",
        "\n",
        "plts = plt1 + plt2 + plt3 + plt4\n",
        "labs = [p.get_label() for p in plts]\n",
        "ax2.legend(plts, labs, loc=0)\n",
        "# fig.tight_layout()\n",
        "fig_name = \"Training and Validation Metrics\"\n",
        "plt.title(fig_name)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "l-AXeoWXoupO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_x, test_y)"
      ],
      "metadata": {
        "id": "iZn1t8UGqxIV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}